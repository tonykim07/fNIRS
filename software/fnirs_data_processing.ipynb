{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIHf1hshYGeF"
      },
      "outputs": [],
      "source": [
        "!pip install nirsimple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBSFz3214eML"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import nirsimple.preprocessing as nsp\n",
        "import nirsimple.processing as nproc\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, age=22, sd_distance=5.0, molar_ext_coeff_table='wray', n_times_buffer=50):\n",
        "        self.AGE = age\n",
        "        self.SD_DISTANCE = sd_distance\n",
        "        self.MOLAR_EXT_COEFF_TABLE = molar_ext_coeff_table\n",
        "        self.n_channels_total = 48\n",
        "        self.n_times_buffer = n_times_buffer\n",
        "        self.raw_buffer = np.zeros((self.n_channels_total, self.n_times_buffer))\n",
        "        self.buffer_initialized = False\n",
        "        self.last_660_packet = None\n",
        "        self.last_940_packet = None\n",
        "\n",
        "        # Build channel names for NIRSimple\n",
        "        physical_channels = []\n",
        "        for set_idx in range(1, 9):\n",
        "            for det in range(1, 4):\n",
        "                physical_channels.append(f\"S{set_idx}_D{det}\")\n",
        "        self.channel_names = []\n",
        "        self.ch_wls = []\n",
        "        for name in physical_channels:\n",
        "            self.channel_names.append(name)   # for 660 nm measurement\n",
        "            self.ch_wls.append(660.0)\n",
        "            self.channel_names.append(name)   # for 940 nm measurement\n",
        "            self.ch_wls.append(940.0)\n",
        "\n",
        "        self.ch_dpfs = [nsp.get_dpf(wl, self.AGE) for wl in self.ch_wls]\n",
        "        self.ch_distances = [self.SD_DISTANCE] * len(self.ch_wls)\n",
        "        self.unit = 'cm'\n",
        "\n",
        "    def combine_packets(self, packet_660, packet_940):\n",
        "        \"\"\"\n",
        "        Combines two 8x5 packets (one for mode 1 and one for mode 2)\n",
        "        into a single sample of 48 values.\n",
        "        For each sensor group (group_id from 1 to 8), the six output values are:\n",
        "            [short_660, short_940, long1_660, long1_940, long2_660, long2_940]\n",
        "        \"\"\"\n",
        "        sample = np.zeros(48)\n",
        "        # Loop through each sensor group in the 660 packet\n",
        "        for i in range(packet_660.shape[0]):\n",
        "            group_id = packet_660[i, 0]\n",
        "            # Find the matching row in the 940 packet\n",
        "            index = np.where(packet_940[:, 0] == group_id)[0][0]\n",
        "            row660 = packet_660[i, :]\n",
        "            row940 = packet_940[index, :]\n",
        "            base = (group_id - 1) * 6\n",
        "            for j in range(3):\n",
        "                sample[base + j * 2]     = row660[1 + j]\n",
        "                sample[base + j * 2 + 1] = row940[1 + j]\n",
        "        return sample\n",
        "\n",
        "    def process_data_packet(self, packet):\n",
        "        \"\"\"\n",
        "        Processes a new 8x5 data packet.\n",
        "\n",
        "        The packet is an 8x5 NumPy array of integers in the form:\n",
        "            [group_id, short, long1, long2, mode]\n",
        "        where mode is expected to be uniform across the packet:\n",
        "            mode = 1 for 660 nm,\n",
        "            mode = 2 for 940 nm.\n",
        "\n",
        "        The packet is stored until both modes are available. Then, it combines\n",
        "        the packets into a 48-element sample, updates the rolling buffer, and\n",
        "        processes the data using the OD conversion, MBLL, and CBSI correction.\n",
        "\n",
        "        Returns a tuple:\n",
        "          (concentration_values_list, table_data)\n",
        "        where table_data is a list of [Channel, Type, Concentration] rows.\n",
        "        If both mode packets are not yet available, it returns None.\n",
        "        \"\"\"\n",
        "        # Determine the mode of the incoming packet\n",
        "        mode = packet[0, 4]\n",
        "        if mode == 1:\n",
        "            self.last_660_packet = packet\n",
        "        elif mode == 2:\n",
        "            self.last_940_packet = packet\n",
        "\n",
        "        if self.last_660_packet is not None and self.last_940_packet is not None:\n",
        "            sample = self.combine_packets(self.last_660_packet, self.last_940_packet)\n",
        "            # Prefill the buffer if it hasn't been initialized yet\n",
        "            if not self.buffer_initialized:\n",
        "                self.raw_buffer = np.tile(sample.reshape(-1, 1), (1, self.n_times_buffer))\n",
        "                self.buffer_initialized = True\n",
        "            else:\n",
        "                # Update the rolling buffer: shift left and insert the new sample\n",
        "                self.raw_buffer = np.roll(self.raw_buffer, -1, axis=1)\n",
        "                self.raw_buffer[:, -1] = sample\n",
        "\n",
        "            # Apply OD Conversion, MBLL, and CBSI correction\n",
        "            delta_od = nsp.intensities_to_od_changes(self.raw_buffer)\n",
        "            delta_c, new_ch_names, new_ch_types = nsp.mbll(\n",
        "                delta_od,\n",
        "                self.channel_names,\n",
        "                self.ch_wls,\n",
        "                self.ch_dpfs,\n",
        "                self.ch_distances,\n",
        "                self.unit,\n",
        "                table=self.MOLAR_EXT_COEFF_TABLE\n",
        "            )\n",
        "            delta_c_corr, corr_ch_names, corr_ch_types = nproc.cbsi(delta_c, new_ch_names, new_ch_types)\n",
        "            concentration_values = delta_c_corr[:, -1]\n",
        "            # Table for showing channel mapping and type\n",
        "            table_data = []\n",
        "            for i, name in enumerate(corr_ch_names):\n",
        "                table_data.append([name, corr_ch_types[i], f\"{concentration_values[i]:.4e} M\"])\n",
        "            return concentration_values.tolist(), table_data\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "# --------------------------------------Example with dummy data generator--------------------------------------------\n",
        "\n",
        "def dummy_packet_generator():\n",
        "    \"\"\"\n",
        "    Dummy generator for 8x5 packets.\n",
        "\n",
        "    Each packet is an 8x5 NumPy array of integers.\n",
        "    Each row corresponds to a sensor group with the following format:\n",
        "        [group_id, short, long1, long2, mode]\n",
        "    Group IDs are 1-indexed. Two types of packets are generated:\n",
        "        mode 1 (660 nm) and mode 2 (940 nm), alternating.\n",
        "\n",
        "    This is the same data format expected from the upstream serial\n",
        "    read function Ingrid is making.\n",
        "    \"\"\"\n",
        "    NUM_GROUPS = 8\n",
        "    base_short = 2400\n",
        "    base_long1 = 2500\n",
        "    base_long2 = 2600\n",
        "    while True:\n",
        "        # Mode 1 packet (660 nm)\n",
        "        packet1 = np.zeros((NUM_GROUPS, 5), dtype=int)\n",
        "        for i in range(NUM_GROUPS):\n",
        "            sensor_group = i + 1\n",
        "            short_val = base_short + int(np.random.randn() * 5)\n",
        "            long1_val = base_long1 + int(np.random.randn() * 5)\n",
        "            long2_val = base_long2 + int(np.random.randn() * 5)\n",
        "            packet1[i] = [sensor_group, short_val, long1_val, long2_val, 1]\n",
        "        yield packet1\n",
        "        time.sleep(1)\n",
        "        # Mode 2 packet (940 nm)\n",
        "        packet2 = np.zeros((NUM_GROUPS, 5), dtype=int)\n",
        "        for i in range(NUM_GROUPS):\n",
        "            sensor_group = i + 1\n",
        "            short_val = base_short + int(np.random.randn() * 5)\n",
        "            long1_val = base_long1 + int(np.random.randn() * 5)\n",
        "            long2_val = base_long2 + int(np.random.randn() * 5)\n",
        "            packet2[i] = [sensor_group, short_val, long1_val, long2_val, 2]\n",
        "        yield packet2\n",
        "        time.sleep(1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    processor = DataProcessor()\n",
        "    dummy_gen = dummy_packet_generator()\n",
        "    print(\"Starting processing.\\n\")\n",
        "    try:\n",
        "        while True:\n",
        "            packet = next(dummy_gen)\n",
        "            result = processor.process_data_packet(packet)\n",
        "            if result is not None:\n",
        "                concentrations, table_data = result\n",
        "                print(\"Latest Concentration Values (48 channels):\")\n",
        "                print(tabulate(table_data, headers=[\"Channel\", \"Type\", \"Concentration\"]))\n",
        "                print(\"-\" * 500)\n",
        "                print(\"Data Sent to GUI Graphing Function: \", concentrations)\n",
        "                print(\"-\" * 500)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopping processing.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
